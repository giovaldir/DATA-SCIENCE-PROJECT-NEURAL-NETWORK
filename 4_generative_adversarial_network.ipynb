{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"name":"4_generative_adversarial_network.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.7 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lzuSQ-tT0caN"},"source":["\n","# Generative Adversarial Networks\n","\n","In this notebook we will be using a pre-trained Generative Adversarial Network from Nvidia \"StyleGAN2\" and generate images. The network was trained on potrait faces, so it is only able to generate a face. \n","\n","For further informations regarding StyleGAN2, you can visit their :\n","- [Paper](https://arxiv.org/abs/1812.04948)\n","- [Youtube Video](https://youtu.be/kSLJriaOumA)\n","- [Source Code](https://github.com/NVlabs/stylegan)\n","- [Face Dataset (FFHQ)](https://github.com/NVlabs/ffhq-dataset)\n","\n","\n","*Notes: Before you go any further, make sure to specify a GPU runtime*"]},{"cell_type":"markdown","metadata":{"id":"XtmvVzVVZzjP"},"source":["___"]},{"cell_type":"code","metadata":{"id":"yZcFAjaz3mw1","cellView":"form"},"source":["#@title Run this to Load StyleGAN2 Pre-Trained Model\n","# Run this for Google CoLab (use TensorFlow 1.x)\n","%tensorflow_version 1.x\n","from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)\n","\n","\n","# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n","#\n","# This work is made available under the Nvidia Source Code License-NC.\n","!git clone https://github.com/NVlabs/stylegan2.git\n","import sys\n","sys.path.insert(0, \"/content/stylegan2\")\n","import dnnlib\n","\n","\n","import argparse\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import re\n","import sys\n","import pretrained_networks\n","\n","from io import BytesIO\n","import IPython.display\n","import numpy as np\n","from math import ceil\n","from PIL import Image, ImageDraw\n","import imageio\n","\n","\n","def expand_seed(seeds, vector_size):\n","  result = []\n","\n","  for seed in seeds:\n","    rnd = np.random.RandomState(seed)\n","    result.append( rnd.randn(1, vector_size) ) \n","  return result\n","\n","def generate_images(Gs, seeds, truncation_psi, prefix):\n","    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n","\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    if truncation_psi is not None:\n","        Gs_kwargs.truncation_psi = truncation_psi\n","\n","    for seed_idx, seed in enumerate(seeds):\n","        print('Generating image for seed %d/%d ...' % (seed_idx, len(seeds)))\n","        rnd = np.random.RandomState(0)\n","        tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n","        images = Gs.run(seed, None, **Gs_kwargs) # [minibatch, height, width, channel]\n","        path = f\"/content/{prefix}-{seed_idx+1}.png\"\n","        PIL.Image.fromarray(images[0], 'RGB').save(path)\n","\n","sc = dnnlib.SubmitConfig()\n","sc.num_gpus = 1\n","sc.submit_target = dnnlib.SubmitTarget.LOCAL\n","sc.local.do_not_copy_source_files = True\n","sc.run_dir_root = \"/content/drive/My Drive/projects/stylegan2\"\n","sc.run_desc = 'generate-images'\n","network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n","\n","print('Loading networks from \"%s\"...' % network_pkl)\n","\n","\n","#@title Utility functions\n","# Useful utility functions...\n","\n","# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n","def generate_images_in_w_space(dlatents, truncation_psi):\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    Gs_kwargs.truncation_psi = truncation_psi\n","    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n","\n","    imgs = []\n","    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n","        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n","        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n","        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n","        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n","    return imgs       \n","\n","def generate_images2(zs, truncation_psi):\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    if not isinstance(truncation_psi, list):\n","        truncation_psi = [truncation_psi] * len(zs)\n","        \n","    imgs = []\n","    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n","        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n","        noise_rnd = np.random.RandomState(1) # fix noise\n","        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n","        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n","        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n","    return imgs\n","\n","def generate_zs_from_seeds(seeds):\n","    zs = []\n","    for seed_idx, seed in enumerate(seeds):\n","        rnd = np.random.RandomState(seed)\n","        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n","        zs.append(z)\n","    return zs\n","\n","# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n","def generate_images_from_seeds(seeds, truncation_psi):\n","    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n","\n","def saveImgs(imgs, location):\n","  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n","    file = location+ str(idx) + \".png\"\n","    img.save(file)\n","\n","def imshow(a, format='png', jpeg_fallback=True):\n","  a = np.asarray(a, dtype=np.uint8)\n","  str_file = BytesIO()\n","  PIL.Image.fromarray(a).save(str_file, format)\n","  im_data = str_file.getvalue()\n","  try:\n","    disp = IPython.display.display(IPython.display.Image(im_data))\n","  except IOError:\n","    if jpeg_fallback and format != 'jpeg':\n","      print ('Warning: image was too large to display in format \"{}\"; '\n","             'trying jpeg instead.').format(format)\n","      return imshow(a, format='jpeg')\n","    else:\n","      raise\n","  return disp\n","\n","def showarray(a, fmt='png'):\n","    a = np.uint8(a)\n","    f = StringIO()\n","    PIL.Image.fromarray(a).save(f, fmt)\n","    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n","\n","        \n","def clamp(x, minimum, maximum):\n","    return max(minimum, min(x, maximum))\n","    \n","def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n","  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n","   \n","  draw = ImageDraw.Draw(buffer)\n","  cy = (y+y2)/2\n","  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n","  for i in range(len(latents)):\n","    mx = x + (x2-x)*(float(i)/len(latents))\n","    h = (y2-y)*latents[i]*0.1\n","    h = clamp(h,cy-y2,y2-cy)\n","    draw.line((mx,cy,mx,cy+h),fill=color)\n","  return PIL.Image.alpha_composite(image,buffer)\n","             \n","  \n","def createImageGrid(images, scale=0.25, rows=1):\n","   w,h = images[0].size\n","   w = int(w*scale)\n","   h = int(h*scale)\n","   height = rows*h\n","   cols = ceil(len(images) / rows)\n","   width = cols*w\n","   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n","   for i,img in enumerate(images):\n","     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n","     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n","   return canvas\n","\n","def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n","  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n","  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n","  for i in range(truncation_cutoff):\n","    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n","    \n","  return dlatent\n","\n","def interpolate(zs, steps):\n","   out = []\n","   for i in range(len(zs)-1):\n","    for index in range(steps):\n","     fraction = index/float(steps) \n","     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n","   return out\n","\n","# Taken from https://github.com/alexanderkuk/log-progress\n","def log_progress(sequence, every=1, size=None, name='Items'):\n","    from ipywidgets import IntProgress, HTML, VBox\n","    from IPython.display import display\n","\n","    is_iterator = False\n","    if size is None:\n","        try:\n","            size = len(sequence)\n","        except TypeError:\n","            is_iterator = True\n","    if size is not None:\n","        if every is None:\n","            if size <= 200:\n","                every = 1\n","            else:\n","                every = int(size / 200)     # every 0.5%\n","    else:\n","        assert every is not None, 'sequence is iterator, set every'\n","\n","    if is_iterator:\n","        progress = IntProgress(min=0, max=1, value=1)\n","        progress.bar_style = 'info'\n","    else:\n","        progress = IntProgress(min=0, max=size, value=0)\n","    label = HTML()\n","    box = VBox(children=[label, progress])\n","    display(box)\n","\n","    index = 0\n","    try:\n","        for index, record in enumerate(sequence, 1):\n","            if index == 1 or index % every == 0:\n","                if is_iterator:\n","                    label.value = '{name}: {index} / ?'.format(\n","                        name=name,\n","                        index=index\n","                    )\n","                else:\n","                    progress.value = index\n","                    label.value = u'{name}: {index} / {size}'.format(\n","                        name=name,\n","                        index=index,\n","                        size=size\n","                    )\n","            yield record\n","    except:\n","        progress.bar_style = 'danger'\n","        raise\n","    else:\n","        progress.bar_style = 'success'\n","        progress.value = index\n","        label.value = \"{name}: {index}\".format(\n","            name=name,\n","            index=str(index or '?')\n","        )\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwYUFHvAKgtJ"},"source":["# Load the GAN Model \n","_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n","noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n","vector_size = Gs.input_shape[1:][0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Mma51xe6b7k"},"source":["# 1. Generate Image using GAN\n","\n","You now have the generator model that can be used to generate images with input of z"]},{"cell_type":"code","metadata":{"id":"BRdAnScjJ6kO"},"source":["import cv2 \n","from google.colab.patches import cv2_imshow\n","\n","# 1. Create random z values \n","random_seed = 0\n","z = expand_seed([random_seed], vector_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FcfPsJx2LuDd"},"source":["# 2. Generate image using z\n","generate_images(Gs, z, 0.5, \"image\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y5zGalYf9lse"},"source":["img = cv2.imread('/content/image-1.png')   \n","cv2_imshow(img) \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fhupoEodF9gS"},"source":["# 2. Latent Space Exploration"]},{"cell_type":"markdown","metadata":{"id":"3fisvltYYBuG"},"source":["## Latent Interpolation "]},{"cell_type":"markdown","metadata":{"id":"RYhseiAuRt6C"},"source":["Here's are several random seed that if it's converted into Z values using our code, it produce an image with glasses "]},{"cell_type":"code","metadata":{"id":"mU17R-JgK7Iy"},"source":["import cv2 \n","from google.colab.patches import cv2_imshow\n","\n","GLASSES = [2,3,17,19,26,40,42,50,44,65,68,70,85,90,96,112,\n","  130,139,140,146,147,152,155,164,176,183,194,198,209,214,215,241,244,245,254,260,\n","  267,296,300,312,313,322,324,331,333,346,361,366,386,401,412,422,425,443,448,472,\n","  487,494,501,516,544,545,551,552,565,568,591,594,595,597,607,610,639,640,669,670,\n","  675,682,703,710,719,730,757,764,765,767,777,780,792,798,799,802,808,812,819,823,\n","  837,857,866,870,881,887,893,894,895,899,915,916,934,936,941,973,979,988,991,993]\n","\n","zs = []\n","for seed in GLASSES:\n","  _z = expand_seed([seed],vector_size)#[0][0]\n","  zs.append(_z)\n","zs= np.array(zs)\n","\n","z1 = zs[0]\n","z2 = zs[10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNKTXKgaR_RB"},"source":["generate_images(Gs, z2, 0.5, \"image\")\n","img = cv2.imread('/content/image-1.png')   \n","cv2_imshow(img) \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cB1JCBgkbTKW"},"source":["imgs = interpolate([z1,z2],10) # generate 5 images\n","\n","for img in imgs:\n","  generate_images(Gs, img, 0.5, \"image\")\n","  img = cv2.imread('/content/image-1.png')   \n","  cv2_imshow(img) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-MTZHYDVZRj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_S7BHN_5iqWx"},"source":["# Style Mixing"]},{"cell_type":"code","metadata":{"id":"u3EHSiypcb9y"},"source":["!python stylegan2/run_generator.py style-mixing-example --network=gdrive:networks/stylegan2-ffhq-config-f.pkl \\\n","  --row-seeds=100,200,300 --col-seeds=400,500,600 --truncation-psi=1.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3IAPfzsLrM_"},"source":["img = cv2.imread('/content/results/00000-style-mixing-example/grid.png')   \n","cv2_imshow(img) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bIhm1L8is79","cellView":"both"},"source":["#@title Manual Style Mixing Reference\n","\n","def style_mixing_example(network_pkl, row_seeds, col_seeds, truncation_psi, col_styles, minibatch_size=4):\n","    print('Loading networks from \"%s\"...' % network_pkl)\n","    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n","    w_avg = Gs.get_var('dlatent_avg') # [component]\n","\n","    Gs_syn_kwargs = dnnlib.EasyDict()\n","    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_syn_kwargs.randomize_noise = False\n","    Gs_syn_kwargs.minibatch_size = minibatch_size\n","\n","    print('Generating W vectors...')\n","    all_seeds = list(set(row_seeds + col_seeds))\n","    all_z = np.stack([np.random.RandomState(seed).randn(*Gs.input_shape[1:]) for seed in all_seeds]) # [minibatch, component]\n","    all_w = Gs.components.mapping.run(all_z, None) # [minibatch, layer, component]\n","    all_w = w_avg + (all_w - w_avg) * truncation_psi # [minibatch, layer, component]\n","    w_dict = {seed: w for seed, w in zip(all_seeds, list(all_w))} # [layer, component]\n","\n","    print('Generating images...')\n","    all_images = Gs.components.synthesis.run(all_w, **Gs_syn_kwargs) # [minibatch, height, width, channel]\n","    image_dict = {(seed, seed): image for seed, image in zip(all_seeds, list(all_images))}\n","\n","    print('Generating style-mixed images...')\n","    for row_seed in row_seeds:\n","        for col_seed in col_seeds:\n","            w = w_dict[row_seed].copy()\n","            w[col_styles] = w_dict[col_seed][col_styles]\n","            image = Gs.components.synthesis.run(w[np.newaxis], **Gs_syn_kwargs)[0]\n","            image_dict[(row_seed, col_seed)] = image\n","\n","    print('Saving images...')\n","    for (row_seed, col_seed), image in image_dict.items():\n","        PIL.Image.fromarray(image, 'RGB').save(dnnlib.make_run_dir_path('%d-%d.png' % (row_seed, col_seed)))\n","\n","    print('Saving image grid...')\n","    _N, _C, H, W = Gs.output_shape\n","    canvas = PIL.Image.new('RGB', (W * (len(col_seeds) + 1), H * (len(row_seeds) + 1)), 'black')\n","    for row_idx, row_seed in enumerate([None] + row_seeds):\n","        for col_idx, col_seed in enumerate([None] + col_seeds):\n","            if row_seed is None and col_seed is None:\n","                continue\n","            key = (row_seed, col_seed)\n","            if row_seed is None:\n","                key = (col_seed, col_seed)\n","            if col_seed is None:\n","                key = (row_seed, row_seed)\n","            canvas.paste(PIL.Image.fromarray(image_dict[key], 'RGB'), (W * col_idx, H * row_idx))\n","    canvas.save(dnnlib.make_run_dir_path('grid.png'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"htO593k0Xal5"},"source":[""],"execution_count":null,"outputs":[]}]}